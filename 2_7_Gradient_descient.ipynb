{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3, 4],\n",
    "                 [5, 6 , 7, 8],\n",
    "                 [9, 10, 11, 12]], dtype = float, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 20.,  40.,  60.,  80.],\n",
      "        [100., 120., 140., 160.],\n",
      "        [180., 200., 220., 240.]], dtype=torch.float64) <- gradient\n"
     ]
    }
   ],
   "source": [
    "function = 10 * (x ** 2).sum() # на выходе получаем скаляр\n",
    "function.backward() # Операция по взятию производной\n",
    "print(x.grad, '<- gradient') # Результат операции backward хранится как оператор x и вызывается x.grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.,  2.,  3.,  4.],\n",
       "         [ 5.,  6.,  7.,  8.],\n",
       "         [ 9., 10., 11., 12.]], dtype=torch.float64, requires_grad=True),\n",
       " tensor(6500., dtype=torch.float64, grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad\n",
    "x.data -= 0.001 * x.grad # x.data это тот же тензор, но он не позволяет брать градиент.\n",
    "                         #Это нужно для корректного вычисления последующих итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_() # При последеющих итерациях градиент будет накапливаться. Для избежания этого, необходимо каждый раз обнулять x.grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([8, 8], dtype = float, requires_grad = True)\n",
    "\n",
    "optimizer = torch.optim.SGD([x], lr  = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_parabola(variable):\n",
    "    return 10 * (variable ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradient_step(function, variable):\n",
    "    function_result = function(variable)\n",
    "    function_result.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    make_gradient_step(function_parabola, x)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача: Реализовать поиск производной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([[5,10],\n",
    "                  [1,2]], dtype = float, requires_grad = True)\n",
    "alpha = 0.001\n",
    "\n",
    "optimizer = torch.optim.SGD([w], lr  = alpha)\n",
    "function = torch.prod(torch.log(torch.log(w + 7)))\n",
    "function.backward()\n",
    "optimizer.step()\n",
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0201, 0.0109],\n",
      "        [0.0449, 0.0351]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.9899, 9.9946],\n",
      "        [0.9775, 1.9824]], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    # critical: calculate the function inside the loop\n",
    "    function = (w + 7).log().log().prod()\n",
    "    function.backward()\n",
    "\n",
    "\n",
    "print(w) # Код для самопроверки, не забудьте закомментировать перед"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
